program: ./algorithms/deep_cfr.py
command:
  - ${env}
  - python3
  - ${program}
  - ${args}
method: bayes
metric:
  name: NashConv
  goal: minimize
parameters:
  iterations:
    value: 1000
  game:
    value: "leduc_poker"
  logfreq:
    value: 1
  num_traversals:
    values: [1500, 30000, 100000]
  batch_size_advantage:
    value: 2048
  batch_size_strategy:
    value: 2048
  num_hidden:
    values: [64, 128, 256]
  num_layers:
    values: [3, 4, 5]
  reinitialize_advantage_networks:
    value: True
  learning_rate:
    value: .001
  memory_capacity:
    value: 1000000
  policy_network_train_steps:
    value: 5000
  advantage_network_train_steps:
    value: 750
early_terminate:
  type: hyperband
  max_iter: 1000
  s: 2
