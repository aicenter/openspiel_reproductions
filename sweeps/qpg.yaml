program: ./algorithms/policy_gradient.py
command:
  - ${env}
  - python3
  - ${program}
  - ${args}
method: bayes
metric:
  name: Exploitability
  goal: minimize
parameters:
  num_episodes:
    value: 8000000
  game:
    value: "kuhn_poker"
  logfreq:
    value: 1000
  loss_str:
    value: "qpg"
  num_hidden:
    values: [64, 128, 256]
  num_layers:
    values: [1, 2, 3, 4, 5]
  batch_size:
    values: [4, 8, 16, 32]
  entropy_cost:
    values: [0, .01, .1, .15, .2]
  num_critic_before_pi:
    values: [16, 32, 64, 128, 256, 512]
  critic_learning_rate:
    values: [.001, .01, .1]
  pi_learning_rate:
    values: [.001, .01, .1]
early_terminate:
  type: hyperband
  max_iter: 8000
  s: 2
# batch_size=16,
# entropy_cost=0.001,
# critic_learning_rate=0.01,
# pi_learning_rate=0.01,
# num_critic_before_pi=4
